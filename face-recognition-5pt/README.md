# Face Recognition with ArcFace ONNX and 5-Point Alignment

A **production-grade, CPU-first face recognition system** using MediaPipe 5-point facial landmark alignment and ArcFace ONNX embeddings. Every stage is explicit, runnable, debuggable, and replaceable.

---

## ğŸ“‹ Quick Start (60 seconds)

### Windows

```bash
# 1. Clone/download the project
# 2. Run setup
setup.bat

# 3. Download model (one-time)
python download_model.py

# 4. Test camera
python -m src.camera

# 5. Enroll a face
python -m src.enroll

# 6. Run recognition
python -m src.recognize
```

### macOS / Linux

```bash
# 1. Clone/download the project
# 2. Run setup
bash setup.sh

# 3. Download model (one-time)
python download_model.py

# 4. Test camera
python -m src.camera

# 5. Enroll a face
python -m src.enroll

# 6. Run recognition
python -m src.recognize
```

---

## ğŸ—ï¸ System Architecture

The system is decomposed into **6 independent, testable stages**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CAMERA    â”‚ Raw video frame
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FACE DETECTION     â”‚ Haar Cascade â†’ Bounding Box
â”‚ (Haar Cascade)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5-POINT LANDMARKS      â”‚ MediaPipe FaceMesh
â”‚ (MediaPipe FaceMesh)    â”‚ â†’ 5 keypoints (L/R eyes, nose, L/R mouth)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ALIGNMENT      â”‚ Similarity Transform
â”‚ (5pt â†’ 112Ã—112) â”‚ â†’ Canonical pose
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EMBEDDING          â”‚ ArcFace ONNX (ResNet-50)
â”‚ (ArcFace ONNX)      â”‚ â†’ 512-dim L2-normalized vector
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MATCHING & DECISION        â”‚
â”‚ Cosine Distance Threshold   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
   â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”
   â”‚ ACCEPT â”‚ or â”‚ REJECT (Unknown)
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ Project Structure

```
face-recognition-5pt/
â”‚
â”œâ”€â”€ data/                          # User data (generated by system)
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ face_db.npz           # Enrolled embeddings (binary)
â”‚   â”‚   â””â”€â”€ face_db.json          # Metadata (human-readable)
â”‚   â”œâ”€â”€ enroll/
â”‚   â”‚   â”œâ”€â”€ Alice/                # Person 1 samples
â”‚   â”‚   â”‚   â”œâ”€â”€ 1767874858183.jpg
â”‚   â”‚   â”‚   â””â”€â”€ 1767874859974.jpg
â”‚   â”‚   â””â”€â”€ Bob/                  # Person 2 samples
â”‚   â”‚       â”œâ”€â”€ 1767874944225.jpg
â”‚   â”‚       â””â”€â”€ 1767874946090.jpg
â”‚   â””â”€â”€ debug_aligned/            # Aligned face crops (optional)
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ embedder_arcface.onnx     # ArcFace model (download required)
â”‚
â”œâ”€â”€ src/                          # Python modules (core pipeline)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                 # All configuration in one place
â”‚   â”œâ”€â”€ camera.py                 # Camera test + FPS validation
â”‚   â”œâ”€â”€ detect.py                 # Haar face detection
â”‚   â”œâ”€â”€ landmarks.py              # MediaPipe 5-point landmarks
â”‚   â”œâ”€â”€ align.py                  # Face alignment (5pt â†’ 112Ã—112)
â”‚   â”œâ”€â”€ embed.py                  # ArcFace embedding extraction
â”‚   â”œâ”€â”€ haar_5pt.py               # Combined Haar + MediaPipe detector
â”‚   â”œâ”€â”€ enroll.py                 # Enrollment pipeline
â”‚   â”œâ”€â”€ evaluate.py               # Threshold evaluation
â”‚   â””â”€â”€ recognize.py              # Live recognition
â”‚
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ setup.bat                     # Windows setup script
â”œâ”€â”€ setup.sh                      # macOS/Linux setup script
â”œâ”€â”€ download_model.py             # Model downloader
â”œâ”€â”€ init_project.py               # Initialize directories
â”œâ”€â”€ .gitignore                    # Git ignore rules
â””â”€â”€ README.md                     # This file
```

---

## ğŸš€ Installation

### Requirements

- **Python 3.9+**
- **Webcam** (USB or built-in)
- **macOS, Linux, or Windows**

### Step 1: Setup Environment

**Windows:**

```bash
setup.bat
```

**macOS/Linux:**

```bash
bash setup.sh
```

This script automatically:

- Creates a virtual environment (`.venv`)
- Installs all dependencies
- Creates necessary directories

### Step 2: Activate Environment

**Windows:**

```bash
.venv\Scripts\activate.bat
```

**macOS/Linux:**

```bash
source .venv/bin/activate
```

### Step 3: Download ArcFace Model

```bash
python download_model.py
```

This downloads the ArcFace/InsightFace w600k_r50.onnx model (~170 MB).

**Manual Download** (if script fails):

1. Download from: https://sourceforge.net/projects/insightface.mirror/files/v0.7/buffalo_l.zip/download
2. Extract: `unzip buffalo_l.zip`
3. Copy: `cp w600k_r50.onnx models/embedder_arcface.onnx`

---

## ğŸ§ª Validation Pipeline

**Run these in order** to validate each stage:

### 1. Camera Validation

```bash
python -m src.camera
```

âœ“ Should display live video with FPS counter
âœ“ Press `q` to exit

### 2. Face Detection

```bash
python -m src.detect
```

âœ“ Should draw green bounding boxes around detected faces
âœ“ Press `q` to exit

### 3. 5-Point Landmarks

```bash
python -m src.landmarks
```

âœ“ Should display 5 green dots: L eye, R eye, nose, L mouth, R mouth
âœ“ Press `q` to exit

### 4. Face Alignment

```bash
python -m src.align
```

âœ“ Should show two windows: original + aligned 112Ã—112 face
âœ“ Press `q` to quit, `s` to save aligned crop

### 5. Embedding Extraction

```bash
python -m src.embed
```

âœ“ Should print embedding dimension (512) and norm
âœ“ Press `q` to quit, `p` to print detailed stats

**If all validation steps pass, the system is ready for enrollment and recognition.**

---

## ğŸ‘¤ Enrollment

Create a face database by enrolling people:

```bash
python -m src.enroll
```

### Workflow

1. Enter person's name (e.g., "Alice")
2. Move your face naturally (left, right, different expressions)
3. Press **SPACE** to capture individual samples
   - Or press **A** to toggle auto-capture mode (0.25 seconds apart)
4. Capture 15+ samples for best accuracy
5. Press **S** to save enrollment

### Controls

| Key   | Action                            |
| ----- | --------------------------------- |
| SPACE | Capture one sample                |
| A     | Toggle auto-capture mode          |
| S     | Save enrollment to database       |
| R     | Reset new samples (keep existing) |
| Q     | Quit                              |

### Output

- **Aligned crops**: `data/enroll/<name>/*.jpg` (for debugging)
- **Database**: `data/db/face_db.npz` (embeddings) + `data/db/face_db.json` (metadata)

### Re-enrollment

Running `enroll` again for the same person will **load existing samples** and **add new ones**. This improves the template over time.

---

## ğŸ“Š Threshold Evaluation

After enrolling 2+ people, evaluate the optimal recognition threshold:

```bash
python -m src.evaluate
```

### Output

- **Genuine distances**: embeddings of same person (should be small, < 0.4)
- **Impostor distances**: embeddings of different people (should be large, > 0.6)
- **Recommended threshold**: optimal distance cutoff for target FAR (False Accept Rate)

### Interpretation

```
Example output:
Genuine distances: mean=0.15 std=0.08
Impostor distances: mean=0.82 std=0.12
Recommended threshold: 0.48 (FAR=1.00%, FRR=3.25%)
```

- **FAR** (False Accept Rate): % of impostors incorrectly accepted
- **FRR** (False Reject Rate): % of genuine users incorrectly rejected

---

## ğŸ¯ Live Recognition

Run real-time face recognition against the enrolled database:

```bash
python -m src.recognize
```

### Display

- Green box + green name: **Enrolled person** (accepted)
- Red box + "Unknown": **Not in database** or distance > threshold
- Confidence bar shows distance

### Controls

| Key | Action                                         |
| --- | ---------------------------------------------- |
| Q   | Quit                                           |
| R   | Reload database (useful after re-enrollment)   |
| +   | Increase threshold (more accepts, higher FAR)  |
| -   | Decrease threshold (fewer accepts, higher FRR) |

### Real-Time Tuning

Use +/- keys to adjust threshold on-the-fly:

- **Too strict?** Press `+` to relax (accept more)
- **Too loose?** Press `-` to tighten (reject more)

---

## âš™ï¸ Configuration

All settings are in `src/config.py`. Key parameters:

### Face Detection

```python
HAAR_SCALE_FACTOR = 1.1           # Detection sensitivity (lower = stricter)
HAAR_MIN_NEIGHBORS = 5             # Require 5 neighbors for stable detection
HAAR_MIN_SIZE = (70, 70)           # Minimum face size (pixels)
```

### 5-Point Landmarks (MediaPipe)

```python
FACEMESH_MIN_DETECTION_CONFIDENCE = 0.5
FACEMESH_MIN_TRACKING_CONFIDENCE = 0.5
```

### Alignment

```python
ALIGNMENT_OUTPUT_SIZE = (112, 112)  # Standard for ArcFace (fixed)
```

### Embedding

```python
EMBEDDING_DIM = 512                 # ArcFace output (fixed)
```

### Recognition

```python
DEFAULT_DISTANCE_THRESHOLD = 0.34   # Adjust based on your evaluate.py output
TARGET_FAR = 0.01                   # Target 1% false accept rate
```

### Enrollment

```python
SAMPLES_NEEDED_FOR_ENROLLMENT = 15  # Recommended for stability
AUTO_CAPTURE_INTERVAL_SECONDS = 0.25
```

---

## ğŸ”§ Troubleshooting

### Camera won't open

```
ERROR: Cannot open camera at index 0
```

**Solution:**

- macOS: System Settings â†’ Privacy & Security â†’ Camera â†’ Allow Terminal/VS Code
- Windows/Linux: Close other apps using the camera
- Try different camera indices: `0`, `1`, `2` in config.py

### Haar cascade not found

```
ERROR: Failed to load cascade from ...
```

**Solution:**

- OpenCV not installed properly
- Run: `pip install --upgrade opencv-python`

### MediaPipe import error

```
ERROR: mediapipe not installed
```

**Solution:**

```bash
pip install mediapipe==0.10.21
```

### ArcFace model missing

```
ERROR: Model not found: models/embedder_arcface.onnx
```

**Solution:**

```bash
python download_model.py
```

### Face detection not working

- Move closer to camera (minimum 60Ã—60 pixels)
- Improve lighting
- Check landmark quality with `python -m src.landmarks`

### Threshold too strict (rejecting everyone)

- Run `python -m src.evaluate` to find optimal threshold
- Or press `+` repeatedly during recognition

### Enrollment database corrupted

- Delete `data/db/face_db.npz` and `data/db/face_db.json`
- Re-enroll from scratch

### Poor recognition accuracy

1. **Check alignment quality**: `python -m src.align`
2. **Check embedding stability**: `python -m src.embed` (cosine sim should be ~0.99 for same face)
3. **Enroll more samples**: 15+ samples per person
4. **Improve enrollment lighting**: Consistent, bright lighting
5. **Re-evaluate threshold**: `python -m src.evaluate`

---

## ğŸ“ˆ Performance

### Typical FPS (on modern CPU)

- Camera capture: 30 FPS
- Face detection: 20-25 FPS
- Landmark extraction: 20-25 FPS
- Alignment: 25-30 FPS
- Embedding extraction: 8-12 FPS _(bottleneck)_
- Recognition (matching): 100+ FPS

**Total recognition pipeline**: 8-10 FPS real-time

### Memory Usage

- Program: ~300 MB RAM
- Database per 100 identities: <5 MB

---

## ğŸ“ Educational Pipeline

This project is designed for **clear understanding**:

1. **Stage 1: Detection** â†’ Understand bounding boxes
2. **Stage 2: Landmarks** â†’ Understand facial geometry
3. **Stage 3: Alignment** â†’ Understand geometric transforms
4. **Stage 4: Embeddings** â†’ Understand neural network outputs
5. **Stage 5: Matching** â†’ Understand similarity metrics
6. **Stage 6: Integration** â†’ Understand complete system

Each stage can be **tested independently** and **replaced** with alternatives.

---

## ğŸ” Security & Privacy

- âœ“ **Runs on CPU** (no cloud, no GPU required)
- âœ“ **Offline** (no internet needed after setup)
- âœ“ **Local storage** (embeddings stored locally, not in cloud)
- âœ“ **No PII** (only embeddings stored, not images)
- âœ“ **Reproducible** (ONNX model is deterministic across platforms)

---

## ğŸ“š References

This project follows the methodology from:

- **Face Recognition with ArcFace ONNX and 5-Point Alignment** by Gabriel Baziramwabo
- InsightFace Project (ArcFace model)
- MediaPipe Face Mesh (landmark detection)
- OpenCV (image processing, Haar cascades)

### Key Papers

1. Deng et al. (2019): _ArcFace: Additive Angular Margin Loss for Deep Face Recognition_ (CVPR)
2. Viola & Jones (2001): _Rapid Object Detection using a Boosted Cascade_ (CVPR)
3. Lugaresi et al. (2019): _MediaPipe: A Framework for Building Perception Pipelines_

---

## ğŸ“ License

This project is provided as-is for educational and research purposes.

---

## ğŸ™‹ Support

If you encounter issues:

1. **Check troubleshooting section** above
2. **Verify all validation steps** pass
3. **Check config.py** for appropriate settings
4. **Check logs** for specific error messages

---

## ğŸ¯ Next Steps

After successful setup:

1. **Understand alignment**: Read comments in `src/align.py`
2. **Understand embeddings**: Read comments in `src/embed.py`
3. **Modify thresholds**: Experiment with `DEFAULT_DISTANCE_THRESHOLD` in `config.py`
4. **Add your own modules**: Extend with face quality checks, anti-spoofing, etc.
5. **Deploy**: Package into standalone application

---

**Happy face recognizing! ğŸ‰**
